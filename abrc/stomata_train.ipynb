{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import os, json, cv2, random, pathlib, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"Open\", \"close\", \"Unknown\"]\n",
    "COLORS = {\n",
    "    \"Open\": (255, 0, 0),  # Red\n",
    "    \"close\": (0, 255, 0),  # Green\n",
    "    \"Unknown\": (0, 0, 255)  # Blue\n",
    "}\n",
    "\n",
    "def filter_annotations(img_dir, label_filename):\n",
    "    r\"\"\" Filter annotations by existing image files in `img_dir` folder\n",
    "    \n",
    "    Returns a dictionary with fields:\n",
    "        \"image\": image file path\n",
    "        \"annotations\": annotation JSON dict with Label studio format. E.g.,\n",
    "            {\n",
    "                \"original_width\": 1920,\n",
    "                \"original_height\": 1280,\n",
    "                \"image_rotation\": 0,\n",
    "                \"value\": {\n",
    "                    \"x\": 3.1,\n",
    "                    \"y\": 8.2,\n",
    "                    \"radiusX\": 20,\n",
    "                    \"radiusY\": 16,\n",
    "                    \"ellipselabels\": [\"Car\"]\n",
    "                }\n",
    "            }\n",
    "    \"\"\"\n",
    "    orig_annotations = None\n",
    "    with open(label_filename, \"r\") as f:\n",
    "        orig_annotations = json.load(f)\n",
    "\n",
    "    annotations = []\n",
    "    for annotation in orig_annotations:\n",
    "        # Process the label file, remove the first 9 random charactors \n",
    "        img_filename = os.path.basename(annotation[\"data\"][\"image\"])[9:]\n",
    "        \n",
    "        # Check whether images exist with TIFF format\n",
    "        filename, file_extension = os.path.splitext(img_filename)\n",
    "        tif_filename = filename + '.tif'\n",
    "        # if TIFF image file name starts with \"2020\", removes it\n",
    "        if tif_filename.startswith(\"2020\"):\n",
    "            tif_filename = tif_filename[4:]\n",
    "        tif_img_filepath = os.path.join(img_dir, tif_filename)\n",
    "        \n",
    "        if os.path.exists(tif_img_filepath):\n",
    "            annotations.append({\n",
    "                \"image\": tif_img_filepath,\n",
    "                \"annotations\": annotation[\"annotations\"][0][\"result\"]\n",
    "            }) \n",
    "        else:\n",
    "            print(\"Not exist: {}\".format(tif_img_filepath))\n",
    "    return annotations\n",
    "\n",
    "def gen_ellipse_from_annotation(label):\n",
    "    r\"\"\"\n",
    "    Generate ellipse from Label Studio ellipse annotation\n",
    "    Warning: this function only handles annotation with \"image_rotation\" = 0, otherwise, return False.\n",
    "\n",
    "    Returns a tuple of\n",
    "        - A bool flag to indicate whether the operation is successful\n",
    "        - ellipse center (x, y)\n",
    "        - ellipse axis (horizontal axis, vertical axis)\n",
    "        - ellipse angle\n",
    "        - category of the annotation\n",
    "\n",
    "    \"\"\"\n",
    "    image_rotation = label[\"image_rotation\"]\n",
    "    if image_rotation != 0:\n",
    "        return False, (0, 0), (0, 0), 0, \"\"\n",
    "    img_w, img_h = label[\"original_width\"], label[\"original_height\"]\n",
    "    rx, ry = label[\"value\"][\"radiusX\"] * img_w / 100, label[\"value\"][\"radiusY\"] * img_h / 100   # horizontal, verticle axies \n",
    "    # According to Label Studio, (x, y) coordinate of the top left corner before rotation (0, 100), but here it is actually the centre, weird.\n",
    "    cx, cy = label[\"value\"][\"x\"] * img_w / 100, label[\"value\"][\"y\"] * img_h / 100\n",
    "    angle = label[\"value\"][\"rotation\"]  # clockwise degree\n",
    "    category = label[\"value\"][\"ellipselabels\"][0]\n",
    "    return True, (cx, cy), (rx, ry), angle, category\n",
    "\n",
    "def gen_polygon_from_annotation(label, delta=10):\n",
    "    r\"\"\" \n",
    "    Generate polygon from Label Studio ellipse annotation\n",
    "    Warning: this function only handles annotation with \"image_rotation\" = 0, otherwise, return False.\n",
    "\n",
    "    Returns a tuple of\n",
    "        - A bool flag to indicate whether the operation is successful\n",
    "        - a closed polygon if successful, otherwise an empty list. E.g, [[x1, y1], [x2, y2], ...]\n",
    "        - category of the annotation\n",
    "\n",
    "    \"\"\"\n",
    "    success, center, axes, angle, category = gen_ellipse_from_annotation(label)\n",
    "    if success:\n",
    "        int_center = (int(center[0]), int(center[1]))\n",
    "        int_axes = (int(axes[0]), int(axes[1]))\n",
    "        int_angle = int(angle)\n",
    "        poly = cv2.ellipse2Poly(center=int_center, axes=int_axes, angle=int_angle, arcStart=0, arcEnd=360, delta=delta)\n",
    "        return True, poly, category\n",
    "    else:\n",
    "        return False, [], \"\"\n",
    "\n",
    "def gen_polygon_w_boundingbox_from_annotation(label, delta=10):\n",
    "    r\"\"\"\n",
    "    Generate polygon and non-rotated bounding_box from Label Studio ellipse annotation\n",
    "    Warning: this function only handles annotation with \"image_rotation\" = 0, otherwise, return False.\n",
    "\n",
    "    Returns a tuple of\n",
    "        - A bool flag to indicate whether the operation is successful\n",
    "        - a closed polygon if successful, otherwise an empty list. E.g, [[x1, y1], [x2, y2], ...]\n",
    "        - a bounding box in the format of (top_left_x, top_left_y, width, height)\n",
    "        - category of the annotation\n",
    "\n",
    "    \"\"\"\n",
    "    success, poly, category = gen_polygon_from_annotation(label, delta)\n",
    "    if success:\n",
    "        # bounding box format: (tlx, tly, w, h)\n",
    "        bb = cv2.boundingRect(poly)\n",
    "        return True, poly, bb, category\n",
    "    else:\n",
    "        return False, [], (0, 0, 0, 0), \"\"\n",
    "    \n",
    "def draw_annotations(img_filename, annotations, draw_polygon=True, draw_boundingbox=True, thickness=1):\n",
    "    img = cv2.imread(img_filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # img_h, img_w = img.shape[:2]\n",
    "    # print(\"Image size = {}\".format((img_h, img_w)))\n",
    "\n",
    "    for v in annotations:\n",
    "        if draw_boundingbox:\n",
    "            success_bb, _, (x, y, w, h), category = gen_polygon_w_boundingbox_from_annotation(v, delta=10)\n",
    "            if success_bb:\n",
    "                cv2.rectangle(img, pt1=(x, y), pt2=(x+w, y+h), color=COLORS[category], thickness=thickness)\n",
    "        if draw_polygon:\n",
    "            success_poly, poly, category = gen_polygon_from_annotation(v)\n",
    "            if success_poly:\n",
    "                cv2.polylines(img, [poly], isClosed=True, thickness=thickness, color=COLORS[category])\n",
    "                # cv2.fillConvexPoly(img, poly, color=COLORS[category])\n",
    "    return img\n",
    "\n",
    "def get_detectron2_dicts(img_dir, json_filename, delta=5):\n",
    "    labelstudio_annotations = filter_annotations(img_dir, json_filename)\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for idx, v in enumerate(labelstudio_annotations):\n",
    "        record = {}\n",
    "        img_filename = v[\"image\"]\n",
    "        annotations = v[\"annotations\"]\n",
    "        img_h, img_w = cv2.imread(img_filename).shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = img_filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = img_h\n",
    "        record[\"width\"] = img_w\n",
    "\n",
    "        objs = []\n",
    "        for anno in annotations:\n",
    "            if anno[\"original_width\"] != record[\"width\"] or anno[\"original_height\"] != record[\"height\"]:\n",
    "                print(\"Generate record error!\")\n",
    "                return []\n",
    "            \n",
    "            success, poly, _, category = gen_polygon_w_boundingbox_from_annotation(anno, delta=delta)\n",
    "            # Convert from [[x1, y1], [x2, y2], ...] to [x1, y1, x2, y2, ...]\n",
    "            px = [x for x, _ in poly]\n",
    "            py = [y for _, y in poly]\n",
    "            poly = [(float(x), float(y)) for x, y in poly]\n",
    "            poly = [p for x in poly for p in x]\n",
    "            if success:\n",
    "                if len(poly) <= 4:\n",
    "                    continue\n",
    "                obj = {\n",
    "                    \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                    \"segmentation\": [poly],\n",
    "                    \"category_id\": 0,  # single category\n",
    "                }\n",
    "                objs.append(obj)\n",
    "            else:\n",
    "                print(\"Generate record error!\")\n",
    "                return []\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    \n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train and val\n",
    "\n",
    "Randomly split data into training (80%) and validation (20%) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_path = pathlib.Path().absolute()\n",
    "dataset_name = \"stomata100\"\n",
    "img_dir = os.path.join(prj_path, \"{}/images\".format(dataset_name))\n",
    "json_filename = os.path.join(prj_path, \"{}/labels/labels.json\".format(dataset_name))\n",
    "labelstudio_annotations = filter_annotations(img_dir, json_filename)\n",
    "\n",
    "# Random Shuffle\n",
    "random.seed(0)\n",
    "images = [v['image'] for v in labelstudio_annotations]\n",
    "random.shuffle(images)\n",
    "\n",
    "# Split\n",
    "train_percentage = 0.8\n",
    "train_num = int(len(images) * train_percentage)\n",
    "\n",
    "# Training set\n",
    "train_dir = os.path.join(prj_path, \"{}/train\".format(dataset_name))\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "for v in images[:train_num]:\n",
    "    dst = os.path.join(train_dir, os.path.basename(v))\n",
    "    shutil.copyfile(v, dst)\n",
    "    \n",
    "# Validation set\n",
    "val_dir = os.path.join(prj_path, \"{}/val\".format(dataset_name))\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "for v in images[train_num:]:\n",
    "    dst = os.path.join(val_dir, os.path.basename(v))\n",
    "    shutil.copyfile(v, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Stomata dataset\n",
    "## Dataset visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the dataset is in correct format, let's visualize the annotations of randomly selected samples in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_path = pathlib.Path().absolute()\n",
    "dataset_name = \"stomata100\"\n",
    "img_dir = os.path.join(prj_path, \"{}/images\".format(dataset_name))\n",
    "json_filename = os.path.join(prj_path, \"{}/labels/labels.json\".format(dataset_name))\n",
    "\n",
    "# Get Detectron2 ground truth\n",
    "for d in [\"train\", \"val\"]:\n",
    "    catelog_name = \"{}_{}\".format(dataset_name, d)\n",
    "    if catelog_name in DatasetCatalog:\n",
    "        DatasetCatalog.remove(catelog_name)\n",
    "    if catelog_name in MetadataCatalog:\n",
    "        MetadataCatalog.remove(catelog_name)\n",
    "    \n",
    "    img_dir = os.path.join(prj_path, \"{}/{}\".format(dataset_name, d))\n",
    "    DatasetCatalog.register(catelog_name, \n",
    "        lambda d=d: get_detectron2_dicts(os.path.join(prj_path, \"{}/{}\".format(dataset_name, d)), json_filename))\n",
    "    MetadataCatalog.get(catelog_name).set(thing_classes=[\"stomata\"])\n",
    "\n",
    "stomata_metadata = MetadataCatalog.get(\"{}_train\".format(dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prj_path = pathlib.Path().absolute()\n",
    "dataset_name = \"stomata100\"\n",
    "img_dir = os.path.join(prj_path, \"{}/images\".format(dataset_name))\n",
    "json_filename = os.path.join(prj_path, \"{}/labels/labels.json\".format(dataset_name))\n",
    "\n",
    "train_dataset_dicts = get_detectron2_dicts(os.path.join(prj_path, \"{}/train\".format(dataset_name)), json_filename, delta=5)\n",
    "\n",
    "# Draw annotation ground truth\n",
    "for idx, d in enumerate(train_dataset_dicts[:5]):\n",
    "    img = cv2.imread(d[\"file_name\"])       \n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=stomata_metadata, scale=1)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Ground truth: {}\".format(os.path.basename(d[\"file_name\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "dataset_name = \"stomata100\"\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"{}_train\".format(dataset_name),)\n",
    "cfg.DATASETS.TEST = (\"{}_val\".format(dataset_name), )\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 8000    # you may need to train longer for a practical dataset 300, 1000?\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (stomata). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.MODEL.DEVICE = \"cpu\"    # train with CPU\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "cfg.OUTPUT_DIR= \"./{}_output_ep{}_{}\".format(dataset_name, cfg.SOLVER.MAX_ITER, dt_string)\n",
    "\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference & evaluation using the trained model\n",
    "\n",
    "Now, let's run inference with the trained model on the stomata validation dataset. First, let's create a predictor using the model we just trained.\n",
    "Inference should use the config with parameters that are used in training\n",
    "cfg now already contains everything we've set previously. We changed it a little bit for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "cfg.INPUT.MIN_SIZE_TEST = 0 # disable resize in testing\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate its performance using AP metric implemented in COCO API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "dataset_name = \"stomata100\"\n",
    "\n",
    "evaluator = COCOEvaluator(\"{}_val\".format(dataset_name), output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"{}_val\".format(dataset_name))\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "70f62ef6fca701886bdfad40a8eb5b32fcff5b6afcf9b492ee89d50a835c2706"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import os, json, cv2, random, pathlib, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "# import helper functions\n",
    "import helper as h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Arguments\n",
    "dataset_path = \"../../google-drive/\"   # root directory of project data\n",
    "dataset_name = \"stomata100\" # name of the dataset \n",
    "output_folder = \"./output\" # folder where to output training and validation results.\n",
    "class_name = \"stomata\"  # name for the class in instance segmentation\n",
    "seed_num = 28825252\n",
    "print_example = False  # switch if to print out exmaple images in the training set.\n",
    "\n",
    "# Initialise Variables\n",
    "label_filenames = {}\n",
    "for d in [\"train\", \"val\"]:\n",
    "    label_filenames[d] = os.path.join(dataset_path, dataset_name, \"labels\", \"labels_{d}.json\")\n",
    "\n",
    "#####################\n",
    "# REGISTER DATASETS #\n",
    "#####################\n",
    "\n",
    "# register training set and validation set using COCO\n",
    "# Note these they can only be registered once.\n",
    "# There is an interesting bug when COCO read JSON files, it should get a list[dict]\n",
    "# however it asserts list[dict] with dict and return an error. Not sure how to solve it.\n",
    "\n",
    "# register_coco_instances(\"train_dataset\", {}, train_label_filename, train_label_filename)\n",
    "# register_coco_instances(\"val_dataset\", {}, val_label_filename, val_img_dir)\n",
    "\n",
    "for d in [\"train\", \"val\"]:\n",
    "    catelog_name = f\"{dataset_name}_{d}\"\n",
    "    if catelog_name in DatasetCatalog:\n",
    "        DatasetCatalog.remove(catelog_name)\n",
    "    if catelog_name in MetadataCatalog:\n",
    "        MetadataCatalog.remove(catelog_name)\n",
    "    \n",
    "    print(\"load \", label_filenames[d], \" to DatasetCatalog...\")\n",
    "    DatasetCatalog.register(catelog_name, lambda d=d: h.get_detectron2_dicts(json_filename = label_filenames[d]))\n",
    "    MetadataCatalog.get(catelog_name).set(thing_classes=[class_name])\n",
    "\n",
    "stomata_metadata = MetadataCatalog.get(f\"{dataset_name}_train\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset visualisation\n",
    "\n",
    "To verify the dataset is in correct format, let's visualize the annotations of randomly selected samples in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset_train_metadata = MetadataCatalog.get(dataset_name + \"_train\")\n",
    "dataset_dicts = DatasetCatalog.get(dataset_name + \"_train\")\n",
    "\n",
    "# Draw annotated examples from training data.\n",
    "if print_example:\n",
    "    num_example = 4\n",
    "    for d in random.sample(dataset_dicts, num_example):\n",
    "        img = cv2.imread(d[\"file_name\"])\n",
    "        visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=1)\n",
    "        out = visualizer.draw_dataset_dict(d)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(out.get_image())\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Ground truth: {}\".format(os.path.basename(d[\"file_name\"])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Set up Detection Configurations\n",
    "\n",
    "Test training configurations and hyperparameters. Important hyper-parameters are:\n",
    "- cfg.SOLVER.IMS_PER_BATCH: batch size\n",
    "- cfg.SOLVER.BASE_LR: learning rate\n",
    "- cfg.SOLVER.STEPS: learning rate decay\n",
    "- \n",
    "\n",
    "See [official documentation](https://detectron2.readthedocs.io/en/latest/modules/config.html) for further information, and [here for transfer learning](https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "\n",
    "> **TODO**   \n",
    "> Here we plan to use `train_net.py` to enable multi-GPU training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (f\"{dataset_name}_train\",)\n",
    "cfg.DATASETS.TEST = (f\"{dataset_name}_val\", )\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 32000 # you may need to train longer for a practical dataset 300, 1000?\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.SOLVER.REFERENCE_WORLD_SIZE = 1    # REFERENCE_WORLD_SIZE * MAX_ITER = TOTAL_ITERATION\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (stomata).\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.MODEL.DEVICE = \"cuda:2\"    # train with CUDA\n",
    "\n",
    "# Create\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "result_dir = os.path.join(output_folder,f\"{dataset_name}_output_ep{int(cfg.SOLVER.MAX_ITER*cfg.SOLVER.REFERENCE_WORLD_SIZE)}_{dt_string}\")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "cfg.OUTPUT_DIR= os.path.join(result_dir, \"train_output\")\n",
    " \n",
    "#print(cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "trainer.train()\n",
    "train_history_output = os.path.join(cfg.OUTPUT_DIR,'train_history.txt')\n",
    "    \n",
    "# THIS IS FOR MLUTIPLE GPUS. DOESN'T WORK AT THE MOMENT\n",
    "#!python ../tools/train_net.py --num-gpus 2  --dist-url \"tcp://100.100.8.127:8989\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference & evaluation using the trained model\n",
    "\n",
    "Now, let's run inference with the trained model on the stomata validation dataset. First, let's create a predictor using the model we just trained.\n",
    "Inference should use the config with parameters that are used in training\n",
    "cfg now already contains everything we've set previously. We changed it a little bit for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained data\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "cfg.INPUT.MIN_SIZE_TEST = 0 # disable resize in testing\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "output_dir = os.path.join(result_dir, \"val_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "evaluator = COCOEvaluator(f\"{dataset_name}_val\", output_dir=output_dir)\n",
    "val_loader = build_detection_test_loader(cfg, f\"{dataset_name}_val\")\n",
    "with open(os.path.join(output_dir, \"val_output.txt\"), \"w\") as f:    \n",
    "    print(\"random_seed: \", seed_num, file = f)\n",
    "    print(\"batch_size: \", cfg.SOLVER.IMS_PER_BATCH, file = f)\n",
    "    print(\"num_iteration: \", cfg.SOLVER.MAX_ITER, file = f)\n",
    "    print(\"processes:\", cfg.SOLVER.REFERENCE_WORLD_SIZE, file = f)\n",
    "    print(inference_on_dataset(predictor.model, val_loader, evaluator),file=f)\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abrc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "471301b95eae577d3e00990a7ba15f83ce91d240593243244dc4cfdecfec7975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

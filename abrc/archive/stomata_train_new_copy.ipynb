{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdetectron2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstructures\u001b[39;00m \u001b[39mimport\u001b[39;00m BoxMode\n\u001b[1;32m     22\u001b[0m \u001b[39m# import helper functions\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhelper\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mh\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helper'"
     ]
    }
   ],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import os, json, cv2, random, pathlib, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "# import helper functions\n",
    "import helper as h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Detectron2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "prj_path = \"../../google-drive/\"   # root directory of Project Data\n",
    "dataset_name = \"stomata100-museum\" # name of the dataset    \n",
    "output_folder = \"./output\"\n",
    "seed_num = 28825252\n",
    "img_dir = os.path.join(prj_path, f\"{dataset_name}/images\")  # get the image directory \n",
    "label_filename = os.path.join(prj_path, f\"{dataset_name}/labels/labels.json\")\n",
    "\n",
    "# get annotations that is ready for detection training and drawing\n",
    "\"\"\"\n",
    "each dictionay consists of these indices:\n",
    " - file_name\n",
    " - image_id\n",
    " - height, \n",
    " - width, \n",
    " - annotations\n",
    "\"\"\"\n",
    "label_dicts = h.get_detectron2_dicts_abrc(img_dir, label_filename) \n",
    "\n",
    "# random Shuffle\n",
    "random.seed(seed_num)\n",
    "random.shuffle(label_dicts)\n",
    "print(\"Randomly shuffle label dicts...\")\n",
    "\n",
    "# split\n",
    "train_percentage = 0.8\n",
    "train_num = int(len(label_dicts) * train_percentage)\n",
    "print(f\"set training number to {train_num} (e.g., {train_percentage*100}% of the dataset)...\")\n",
    "\n",
    "# initialise variables\n",
    "label_cat = {}\n",
    "img_dirs = {}\n",
    "label_filenames = {}\n",
    "label_cat['train'] = label_dicts[:train_num]\n",
    "label_cat['val'] = label_dicts[train_num:]\n",
    "\n",
    "\n",
    "#######################################\n",
    "# PREPARE TRAINING AND VALIDATION SET #\n",
    "#######################################\n",
    "\n",
    "for d in [\"train\", \"val\"]:\n",
    "    img_dirs[d] = os.path.join(prj_path, f\"{dataset_name}/{d}\")\n",
    "    label_filenames[d] = os.path.join(prj_path, f\"{dataset_name}/labels/labels_{d}.json\")\n",
    "    # reset /train folder\n",
    "    shutil.rmtree(img_dirs[d])\n",
    "    os.makedirs(img_dirs[d], exist_ok=True)\n",
    "    # reset label_train.json\n",
    "    open(label_filenames[d], 'w').close()\n",
    "    with open(label_filenames[d], 'a') as f:\n",
    "        f.write('[')\n",
    "    # extract training and validation imgs and labels from /images and labels.json\n",
    "    for idx, v in enumerate(label_cat[d]):\n",
    "        # copy training set from images to /train\n",
    "        dst = os.path.join(img_dirs[d], os.path.basename(v[\"file_name\"]))\n",
    "        shutil.copyfile(v[\"file_name\"], dst)\n",
    "        # save dict to label_train.json\n",
    "        with open(label_filenames[d], 'a') as f:\n",
    "            json.dump(v, f)\n",
    "            if idx < len(label_cat[d]) - 1:\n",
    "                f.write(',')\n",
    "    with open(label_filenames[d], 'a') as f:\n",
    "        f.write(']')\n",
    "        f.close()\n",
    "        \n",
    "\n",
    "#####################\n",
    "# REGISTER DATASETS #\n",
    "#####################\n",
    "\n",
    "# register training set and validation set using COCO\n",
    "# Note these they can only be registered once.\n",
    "# There is an interesting bug when COCO read JSON files, it should get a list[dict]\n",
    "# however it asserts list[dict] with dict and return an error. Not sure how to solve it.\n",
    "\n",
    "# register_coco_instances(\"train_dataset\", {}, train_label_filename, train_label_filename)\n",
    "# register_coco_instances(\"val_dataset\", {}, val_label_filename, val_img_dir)\n",
    "\n",
    "for d in [\"train\", \"val\"]:\n",
    "    catelog_name = f\"{dataset_name}_{d}\"\n",
    "    if catelog_name in DatasetCatalog:\n",
    "        DatasetCatalog.remove(catelog_name)\n",
    "    if catelog_name in MetadataCatalog:\n",
    "        MetadataCatalog.remove(catelog_name)\n",
    "    \n",
    "    print(\"load \", label_filenames[d], \" to DatasetCatalog...\")\n",
    "    #DatasetCatalog.register(catelog_name, lambda d=d: h.get_detectron2_dicts_raw(img_dir[d],label_filename, delta=5))\n",
    "    DatasetCatalog.register(catelog_name, lambda d=d: h.get_detectron2_dicts(json_filename = label_filenames[d]))\n",
    "    MetadataCatalog.get(catelog_name).set(thing_classes=[\"stomata\"])\n",
    "\n",
    "stomata_metadata = MetadataCatalog.get(\"{}_train\".format(dataset_name))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset visualisation\n",
    "\n",
    "To verify the dataset is in correct format, let's visualize the annotations of randomly selected samples in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset_train_metadata = MetadataCatalog.get(dataset_name + \"_train\")\n",
    "dataset_dicts = DatasetCatalog.get(dataset_name + \"_train\")\n",
    "\n",
    "print_example = False\n",
    "\n",
    "# Draw annotated examples from training data.\n",
    "if print_example:\n",
    "    num_example = 4\n",
    "    for d in random.sample(dataset_dicts, num_example):\n",
    "        img = cv2.imread(d[\"file_name\"])\n",
    "        visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=1)\n",
    "        out = visualizer.draw_dataset_dict(d)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(out.get_image())\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Ground truth: {}\".format(os.path.basename(d[\"file_name\"])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### STEP 1: Set Training Parameters\n",
    "\n",
    "Here we use `train_net.py` to enable multi-GPU training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (f\"{dataset_name}_train\",)\n",
    "cfg.DATASETS.TEST = (f\"{dataset_name}_val\", )\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 64000 # you may need to train longer for a practical dataset 300, 1000?\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.SOLVER.REFERENCE_WORLD_SIZE = 1    # REFERENCE_WORLD_SIZE * MAX_ITER = TOTAL_ITERATION\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (stomata). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.MODEL.DEVICE = \"cuda:0\"    # train with CUDA\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "result_dir = os.path.join(output_folder,f\"{dataset_name}_output_ep{int(cfg.SOLVER.MAX_ITER*cfg.SOLVER.REFERENCE_WORLD_SIZE)}_{dt_string}\")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "cfg.OUTPUT_DIR= os.path.join(result_dir, \"train_output\")\n",
    " \n",
    "#print(cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "trainer.train()\n",
    "train_history_output = os.path.join(cfg.OUTPUT_DIR,'train_history.txt')\n",
    "    \n",
    "# THIS IS FOR MLUTIPLE GPUS. DOESN'T WORK AT THE MOMENT\n",
    "#!python ../tools/train_net.py --num-gpus 2  --dist-url \"tcp://100.100.8.127:8989\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference & evaluation using the trained model\n",
    "\n",
    "Now, let's run inference with the trained model on the stomata validation dataset. First, let's create a predictor using the model we just trained.\n",
    "Inference should use the config with parameters that are used in training\n",
    "cfg now already contains everything we've set previously. We changed it a little bit for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "cfg.INPUT.MIN_SIZE_TEST = 0 # disable resize in testing\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "output_dir = os.path.join(result_dir, \"val_output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "evaluator = COCOEvaluator(f\"{dataset_name}_val\", output_dir=output_dir)\n",
    "val_loader = build_detection_test_loader(cfg, f\"{dataset_name}_val\")\n",
    "with open(os.path.join(output_dir, \"val_output.txt\"), \"w\") as f:    \n",
    "    print(\"random_seed: \", seed_num, file = f)\n",
    "    print(\"batch_size: \", cfg.SOLVER.IMS_PER_BATCH, file = f)\n",
    "    print(\"num_iteration: \", cfg.SOLVER.MAX_ITER, file = f)\n",
    "    print(\"processes:\", cfg.SOLVER.REFERENCE_WORLD_SIZE, file = f)\n",
    "    print(inference_on_dataset(predictor.model, val_loader, evaluator),file=f)\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abrc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "471301b95eae577d3e00990a7ba15f83ce91d240593243244dc4cfdecfec7975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

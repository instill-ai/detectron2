{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418fe0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "import os, json, cv2, random, pathlib, shutil\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "import helper as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754de32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Intput Arguments\n",
    "seed = 0\n",
    "dataset_path = \"../../google-drive/\"\n",
    "dataset_name = \"stomata200-mix\"\n",
    "dataset_postfix = '_val' # this can be set to [\"\", \"_train\", \"_val\", \"_test\"]\n",
    "model_folder_name = \"stomata200-mix_output_ep32000_2023_02_14_19_32_50\"\n",
    "test_threshold = 0.3 # this is the detection threshold\n",
    "test_img_dir = \"../../google-drive/stomata100-museum/images\" # This can be any folder consisting of images.\n",
    "test_img_num = 2 # set to None if you wish to run through the whole directory.\n",
    "\n",
    "# check if test_img_num is valid\n",
    "total_img_num = len([entry for entry in os.listdir(test_img_dir) if os.path.isfile(os.path.join(test_img_dir, entry))])\n",
    "if test_img_num > total_img_num:\n",
    "    print(f\"test_img_num is too large. There are only {total_img_num} in {test_img_dir}\")\n",
    "\n",
    "CATEGORIES = [\"Open\", \"close\", \"Unknown\"]\n",
    "INST_CATEGORIES = [\"stomata\"]\n",
    "COLORS = {\n",
    "    \"Open\": (0, 255, 0),  # Green\n",
    "    \"close\": (255, 0, 0),  # Red\n",
    "    \"Unknown\": (0, 0, 255)  # Blue\n",
    "}\n",
    "\n",
    "# Ensure you have \n",
    "DRAW_THICKNESS = {\n",
    "    \"stomata100\": 2,\n",
    "    \"stomata100-museum\": 2,\n",
    "    \"stomata200-mix\": 2\n",
    "}\n",
    "\n",
    "if dataset_name not in DRAW_THICKNESS:\n",
    "    print(\"dataset-Name is not defeind in DRAW_THICKNESS. Check if it is properly set.\")\n",
    "\n",
    "# Set Variables\n",
    "random.seed(seed)\n",
    "label_filename = os.path.join(dataset_path, dataset_name, \"labels\", f\"labels{dataset_postfix}.json\")\n",
    "if os.path.isfile(label_filename) == False:\n",
    "    print(f\"Label file, {label_filename}, does not exist. Please check if the arguments above are correct and ensure that you have prepared the dataset with data_preparation.ipynb. Read READ.me for further information.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c058bd5f",
   "metadata": {},
   "source": [
    "## Register Dataset and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee2b5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We actually don't need to register DatasetCatelog here but let's ignore it for now.\n",
    "for d in [\"train\", \"val\"]:\n",
    "    catelog_name = \"{}_{}\".format(dataset_name, d)\n",
    "    if catelog_name in DatasetCatalog:\n",
    "        DatasetCatalog.remove(catelog_name)\n",
    "    if catelog_name in MetadataCatalog:\n",
    "        MetadataCatalog.remove(catelog_name)\n",
    "    \n",
    "    img_dir = os.path.join(dataset_path, catelog_name)\n",
    "    DatasetCatalog.register(catelog_name, \n",
    "        lambda d=d: h.get_detectron2_dicts(os.path.join(dataset_path, dataset_name, d), label_filename))\n",
    "    MetadataCatalog.get(catelog_name).set(thing_classes=INST_CATEGORIES)\n",
    "\n",
    "stomata_metadata = MetadataCatalog.get(\"{}_train\".format(dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98d4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (f\"{dataset_name}_train\",)\n",
    "cfg.DATASETS.TEST = (f\"{dataset_name}_val\", )\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1000    # you may need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (stomata). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.MODEL.DEVICE = \"cuda\"    # deploy model to device\n",
    "\n",
    "cfg.OUTPUT_DIR = os.path.join(\"output\",model_folder_name,\"train_output\")\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = test_threshold  # set a custom testing threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3772ecbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/17 15:16:13 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from output/stomata200-mix_output_ep32000_2023_02_14_19_32_50/train_output/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pychen/anaconda3/envs/abrc/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# set up save directory\n",
    "save_dir = os.path.join(\n",
    "    dataset_path, \"inference_outputs\", dataset_name, f\"{model_folder_name}_inference\", f\"thres_{cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST}\")\n",
    "shutil.rmtree(save_dir, ignore_errors=True)\n",
    "os.makedirs(save_dir)\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Get inference dicts\n",
    "infer_dicts = h.get_inference_dicts(img_dir=test_img_dir)\n",
    "random.shuffle(infer_dicts)\n",
    "\n",
    "# Start inferencing\n",
    "for idx, d in enumerate(infer_dicts[:test_img_num]):\n",
    "    img_filename = d[\"file_name\"] \n",
    "    im = cv2.imread(img_filename)\n",
    "    outputs = predictor(im)  \n",
    "    # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "\n",
    "    # instance_mode=ColorMode.IMAGE_BW \n",
    "    # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                    metadata=stomata_metadata,\n",
    "                    scale=1,\n",
    "\n",
    "        )\n",
    "    \n",
    "    # `.to.(cpu)` is to transform datatype from tensor to numpy.array.\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    # INSTANCE SEGMENTATION\n",
    "    # Draw estimated INST SEG on images\n",
    "    fig = plt.figure(figsize=(12, 8), dpi=600)\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Pred: {}\".format(os.path.basename(d[\"file_name\"])))\n",
    "    \n",
    "    filename, file_extension = os.path.splitext(os.path.basename(d[\"file_name\"]))\n",
    "    # Set file extension to JPEG\n",
    "    file_extension = \".jpg\"\n",
    "    \n",
    "    # Save instance segmentation results\n",
    "    save_filename = os.path.join(\n",
    "        save_dir, \n",
    "        \"{}_thres_{}_inst_seg{}\".format(filename, cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST, file_extension))\n",
    "    cv2.imwrite(save_filename, cv2.cvtColor(out.get_image(), cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # ROTATED BBOX\n",
    "    # Draw estimated ROTATED BBOX on images\n",
    "    pred_masks = outputs['instances'].pred_masks\n",
    "    pred_categories = outputs['instances'].pred_classes\n",
    "    pred_scores = outputs['instances'].scores\n",
    "    polygons, categories = [], []\n",
    "    for mask, category, score in zip(pred_masks, pred_categories, pred_scores):\n",
    "        po = h.binary_mask_to_polygon(mask.cpu())\n",
    "        polygons += po\n",
    "        categories += [\"{} {:.0%}\".format(INST_CATEGORIES[category], score)] * len(po)\n",
    "    \n",
    "    # Draw fitted ROTATED BBOX\n",
    "    fitted_rbboxs = h.fit_polygens_to_rotated_bboxes(polygons)\n",
    "\n",
    "    img_draw = h.draw_rotated_bboxes(img_filename, fitted_rbboxs, categories, thickness=DRAW_THICKNESS[dataset_name], color=None)\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(img_draw)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Pred_rotated_bboxes: {}\".format(os.path.basename(d[\"file_name\"])))\n",
    "    \n",
    "    # Save ROTATED_BBOX result to file\n",
    "    save_filename = os.path.join(\n",
    "        save_dir, \n",
    "        \"{}_thres_{}_rotated_bbox{}\".format(filename, cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST, file_extension))\n",
    "    cv2.imwrite(save_filename, cv2.cvtColor(img_draw, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # OUTPUT RESULTS FOR BOTH TASKS\n",
    "    # Save both INST SEG and ROTATED BBOX results to file.\n",
    "    save_filename = os.path.join(\n",
    "        save_dir, \n",
    "        \"benchmark_{}_thres_{}{}\".format(filename, cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST, file_extension))\n",
    "    fig.savefig(save_filename, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abrc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "471301b95eae577d3e00990a7ba15f83ce91d240593243244dc4cfdecfec7975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

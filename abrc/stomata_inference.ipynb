{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418fe0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "import os, json, cv2, random, pathlib, shutil\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.visualizer import ColorMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754de32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "CATEGORIES = [\"Open\", \"close\", \"Unknown\"]\n",
    "INST_CATEGORIES = [\"stomata\"]\n",
    "COLORS = {\n",
    "    \"Open\": (0, 255, 0),  # Green\n",
    "    \"close\": (255, 0, 0),  # Red\n",
    "    \"Unknown\": (0, 0, 255)  # Blue\n",
    "}\n",
    "\n",
    "def random_color():\n",
    "    return [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
    "\n",
    "\n",
    "def get_detectron2_dicts(img_dir, json_filename, delta=5):\n",
    "    labelstudio_annotations = filter_annotations(img_dir, json_filename)\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for idx, v in enumerate(labelstudio_annotations):\n",
    "        record = {}\n",
    "        img_filename = v[\"image\"]\n",
    "        annotations = v[\"annotations\"]\n",
    "        img_h, img_w = cv2.imread(img_filename).shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = img_filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = img_h\n",
    "        record[\"width\"] = img_w\n",
    "\n",
    "        objs = []\n",
    "        for anno in annotations:\n",
    "            if anno[\"original_width\"] != record[\"width\"] or anno[\"original_height\"] != record[\"height\"]:\n",
    "                print(\"Generate record error!\")\n",
    "                return []\n",
    "            \n",
    "            success, poly, _, category = gen_polygon_w_boundingbox_from_annotation(anno, delta=delta)\n",
    "            # Convert from [[x1, y1], [x2, y2], ...] to [x1, y1, x2, y2, ...]\n",
    "            px = [x for x, _ in poly]\n",
    "            py = [y for _, y in poly]\n",
    "            poly = [(float(x), float(y)) for x, y in poly]\n",
    "            poly = [p for x in poly for p in x]\n",
    "            if success:\n",
    "                if len(poly) <= 4:\n",
    "                    continue\n",
    "                obj = {\n",
    "                    \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                    \"segmentation\": [poly],\n",
    "                    \"category_id\": 0,  # single category\n",
    "                }\n",
    "                objs.append(obj)\n",
    "            else:\n",
    "                print(\"Generate record error!\")\n",
    "                return []\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    \n",
    "    return dataset_dicts\n",
    "\n",
    "\n",
    "def get_inference_dicts(img_dir, extensions=None):\n",
    "    if extensions is None:\n",
    "        extensions = [\".png\", \".tif\", \"jpg\"]\n",
    "        \n",
    "    dataset_dicts = []\n",
    "    img_idx = 0\n",
    "    for ext in extensions:\n",
    "        for fname in os.listdir(img_dir):\n",
    "            # check the file ends with the extension\n",
    "            if fname.endswith(ext):\n",
    "                img_filepath = os.path.join(img_dir, fname)\n",
    "                record = {}\n",
    "                img_h, img_w = cv2.imread(img_filepath).shape[:2]\n",
    "                record[\"file_name\"] = img_filepath\n",
    "                record[\"image_id\"] = img_idx\n",
    "                record[\"height\"] = img_h\n",
    "                record[\"width\"] = img_w\n",
    "                \n",
    "                dataset_dicts.append(record)\n",
    "                img_idx += 1\n",
    "    return dataset_dicts\n",
    "\n",
    "def binary_mask_to_polygon(binary_mask, tolerance=0):\n",
    "    r\"\"\" Converts a binary mask to COCO polygon representation\n",
    "    Args:\n",
    "        binary_mask: a 2D binary numpy array where '1's represent the object\n",
    "        tolerance: Maximum distance from original points of polygon to approximated polygonal chain. If tolerance is 0, the original coordinate array is returned.\n",
    "    \n",
    "    \"\"\"\n",
    "    def close_contour(contour):\n",
    "        if not np.array_equal(contour[0], contour[-1]):\n",
    "            contour = np.vstack((contour, contour[0]))\n",
    "        return contour\n",
    "    \n",
    "    polygons = []\n",
    "    # pad mask to close contours of shapes which start and end at an edge\n",
    "    padded_binary_mask = np.pad(binary_mask, pad_width=1, mode='constant', constant_values=0)\n",
    "    contours = measure.find_contours(padded_binary_mask, 0.5)\n",
    "    for contour in contours:\n",
    "        contour = close_contour(contour)\n",
    "        if len(contour) < 3:\n",
    "            continue\n",
    "        contour = np.flip(contour, axis=1)\n",
    "        segmentation = contour.ravel().tolist()\n",
    "        # after padding and subtracting 1 we may get -0.5 points in our segmentation\n",
    "#         segmentation = [0 if i < 0 else i for i in segmentation]\n",
    "        polygons.append(segmentation)\n",
    "    return polygons\n",
    "\n",
    "def fit_polygens_to_rotated_bboxes(polygons):\n",
    "    rbboxes = []\n",
    "    for p in polygons:\n",
    "        pts_x = p[::2]\n",
    "        pts_y = p[1::2]\n",
    "        pts = [[x, y] for x,y in zip(pts_x, pts_y)]\n",
    "        pts = np.array(pts, np.float32)\n",
    "        rect = cv2.minAreaRect(pts)  #  ((cx, cy), (w, h), a)\n",
    "        rbboxes.append(rect)\n",
    "    return rbboxes\n",
    "\n",
    "def draw_polygons(img_filename, polygons, texts, thickness=1):\n",
    "    img = cv2.imread(img_filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    tl = thickness\n",
    "    tf = max(tl-1, 1)\n",
    "    for p, text in zip(polygons, texts):\n",
    "        color = random_color()\n",
    "        pts_x = p[::2]\n",
    "        pts_y = p[1::2]\n",
    "        pts = [[x, y] for x,y in zip(pts_x, pts_y)]\n",
    "        pts = np.array(pts, np.int32)\n",
    "        cv2.polylines(img, [pts], isClosed=True, thickness=thickness, color=color)\n",
    "        # bounding box format: (tlx, tly, w, h)\n",
    "        x, y, w, h = cv2.boundingRect(pts)\n",
    "        cv2.rectangle(img, pt1=(x, y), pt2=(x+w, y+h), color=color, thickness=thickness, lineType=cv2.LINE_AA)\n",
    "        t_size = cv2.getTextSize(text, 0, fontScale=tl/3, thickness=thickness)[0]\n",
    "        c1 = (x, y)\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] -3\n",
    "        cv2.rectangle(img, c1, c2, color=color, thickness=-1, lineType=cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img, text, (c1[0], c1[1]-2), 0, tl/3, [255,255,255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "def draw_rotated_bboxes(img_filename, rboxes, texts, thickness=1, color=None):\n",
    "    img = cv2.imread(img_filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = draw_rotated_bboxes_on_image(img, rboxes, texts, thickness, color)\n",
    "    return img\n",
    "\n",
    "def draw_rotated_bboxes_on_image(img, rboxes, texts, thickness=1, color=None):\n",
    "    img_draw = img.copy()\n",
    "    tl = thickness\n",
    "    tf = max(tl-1, 1)\n",
    "    for rb, text in zip(rboxes, texts):\n",
    "        c = random_color() if color is None else color\n",
    "        box = cv2.boxPoints(rb)\n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(img_draw, [box], 0, color=c, thickness=thickness)\n",
    "        t_size = cv2.getTextSize(text, 0, fontScale=tl/3, thickness=thickness)[0]\n",
    "        pt = np.amin(box, axis=0)\n",
    "        c1 = (pt[0], pt[1])\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] -3\n",
    "        cv2.rectangle(img_draw, c1, c2, color=color, thickness=-1, lineType=cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img_draw, text, (c1[0], c1[1]-2), 0, tl/3, [255,255,255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    return img_draw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_path = \"../../google-drive/\"\n",
    "dataset_name = \"stomata100\"\n",
    "\n",
    "json_filename = os.path.join(prj_path, \"{}/labels/labels.json\".format(dataset_name))\n",
    "\n",
    "# Get Detectron2 ground truth\n",
    "for d in [\"train\", \"val\"]:\n",
    "    catelog_name = \"{}_{}\".format(dataset_name, d)\n",
    "    if catelog_name in DatasetCatalog:\n",
    "        DatasetCatalog.remove(catelog_name)\n",
    "    if catelog_name in MetadataCatalog:\n",
    "        MetadataCatalog.remove(catelog_name)\n",
    "    \n",
    "    img_dir = os.path.join(prj_path, catelog_name)\n",
    "    DatasetCatalog.register(catelog_name, \n",
    "        lambda d=d: get_detectron2_dicts(os.path.join(prj_path, \"{}/{}\".format(dataset_name, d)), json_filename))\n",
    "    MetadataCatalog.get(catelog_name).set(thing_classes=INST_CATEGORIES)\n",
    "\n",
    "stomata_metadata = MetadataCatalog.get(\"{}_train\".format(dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "\n",
    "dataset_name = \"stomata100\"\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"{}_train\".format(dataset_name),)\n",
    "cfg.DATASETS.TEST = (\"{}_val\".format(dataset_name), )\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1000    # you may need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (stomata). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.MODEL.DEVICE = \"cpu\"    # train with CPU\n",
    "\n",
    "\n",
    "model_folder_name = \"stomata100_output_ep8000_2022_10_06_04_36_29\"\n",
    "cfg.OUTPUT_DIR = \"./{}\".format(model_folder_name)\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772ecbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset_name = \"2021_Aono_PlosOne_Maize\"\n",
    "# dataset_name = \"2021_Zhu_FPS_Wheat_10x\"\n",
    "dataset_name = \"2021_Zhu_FPS_Wheat_20x\"\n",
    "# dataset_name = \"2022_Li_PC_LeafNet\"\n",
    "\n",
    "thickness = {\n",
    "    \"2021_Aono_PlosOne_Maize\": 5,\n",
    "    \"2021_Zhu_FPS_Wheat_10x\": 2,\n",
    "    \"2021_Zhu_FPS_Wheat_20x\": 2,\n",
    "    \"2022_Li_PC_LeafNet\": 2\n",
    "}\n",
    "\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3   # set a custom testing threshold\n",
    "\n",
    "save_dir = os.path.join(\n",
    "    prj_path, \n",
    "    \"{}/{}_inference/thres_{}\".format(dataset_name, model_folder_name, cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST))\n",
    "shutil.rmtree(save_dir, ignore_errors=True)\n",
    "os.makedirs(save_dir)\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "prj_path = pathlib.Path().absolute().parent\n",
    "full_img_dir = os.path.join(prj_path, \"{}/images\".format(dataset_name))\n",
    "\n",
    "# Get inference dicts\n",
    "infer_dicts = get_inference_dicts(img_dir=full_img_dir)\n",
    "\n",
    "for idx, d in enumerate(infer_dicts):\n",
    "    img_filename = d[\"file_name\"] \n",
    "    im = cv2.imread(img_filename)\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                    metadata=stomata_metadata,\n",
    "                    scale=1,\n",
    "#                     instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "        )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    # Show predictions\n",
    "    fig = plt.figure(figsize=(12, 8), dpi=600)\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Pred: {}\".format(os.path.basename(d[\"file_name\"])))\n",
    "    \n",
    "    filename, file_extension = os.path.splitext(os.path.basename(d[\"file_name\"]))\n",
    "   # Set file extension to JPEG\n",
    "    file_extension = \".jpg\"\n",
    "    save_filename = os.path.join(\n",
    "        save_dir, \n",
    "        \"{}_thres_{}_inst_seg{}\".format(filename, cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST, file_extension))\n",
    "    cv2.imwrite(save_filename, cv2.cvtColor(out.get_image(), cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Draw estimated rotated bounding boxes on images\n",
    "    pred_masks = outputs['instances'].pred_masks\n",
    "    pred_categories = outputs['instances'].pred_classes\n",
    "    pred_scores = outputs['instances'].scores\n",
    "    polygons, categories = [], []\n",
    "    for mask, category, score in zip(pred_masks, pred_categories, pred_scores):\n",
    "        po = binary_mask_to_polygon(mask)\n",
    "        polygons += po\n",
    "        categories += [\"{} {:.0%}\".format(INST_CATEGORIES[category], score)] * len(po)\n",
    "    \n",
    "#     img_draw = draw_polygons(img_filename, polygons, categories, thickness=thickness[dataset_name])\n",
    "#     fig.add_subplot(3, 1, 2)\n",
    "#     plt.imshow(img_draw)\n",
    "#     plt.axis('off')\n",
    "#     plt.title(\"Pred_poly: {}\".format(os.path.basename(d[\"file_name\"])))\n",
    "\n",
    "    # Draw fitted bounding boxes\n",
    "    fitted_rbboxs = fit_polygens_to_rotated_bboxes(polygons)\n",
    "#     print(\"Fitted rotated bounding boxes: \")\n",
    "#     for i, rbox in enumerate(fitted_rbboxs):\n",
    "#         print(i, rbox)\n",
    "    img_draw = draw_rotated_bboxes(img_filename, fitted_rbboxs, categories, thickness=thickness[dataset_name], color=None)\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(img_draw)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Pred_rotated_bboxes: {}\".format(os.path.basename(d[\"file_name\"])))\n",
    "    save_filename = os.path.join(\n",
    "        save_dir, \n",
    "        \"{}_thres_{}_rotated_bbox{}\".format(filename, cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST, file_extension))\n",
    "    cv2.imwrite(save_filename, cv2.cvtColor(img_draw, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    \n",
    "#     # Show original image\n",
    "#     fig.add_subplot(1, 3, 3)\n",
    "#     rgb_im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "#     plt.imshow(rgb_im)\n",
    "#     plt.axis('off')\n",
    "#     plt.title(\"Original: {}\".format(os.path.basename(d[\"file_name\"])))\n",
    "    \n",
    "    save_filename = os.path.join(\n",
    "        save_dir, \n",
    "        \"benchmark_{}_thres_{}{}\".format(filename, cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST, file_extension))\n",
    "    fig.savefig(save_filename, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abrc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "471301b95eae577d3e00990a7ba15f83ce91d240593243244dc4cfdecfec7975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fe0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "import os, json, cv2, random, pathlib, shutil\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.visualizer import ColorMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754de32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"Open\", \"close\", \"Unknown\"]\n",
    "COLORS = {\n",
    "    \"Open\": (0, 255, 0),  # Green\n",
    "    \"close\": (255, 0, 0),  # Red\n",
    "    \"Unknown\": (0, 0, 255)  # Blue\n",
    "}\n",
    "\n",
    "def random_color():\n",
    "    return [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
    "\n",
    "def filter_annotations(img_dir, label_filename):\n",
    "    r\"\"\" Filter annotations by existing image files in `img_dir` folder\n",
    "    \n",
    "    Returns a dictionary with fields:\n",
    "        \"image\": image file path\n",
    "        \"annotations\": annotation JSON dict with Label studio format. E.g.,\n",
    "            {\n",
    "                \"original_width\": 1920,\n",
    "                \"original_height\": 1280,\n",
    "                \"image_rotation\": 0,\n",
    "                \"value\": {\n",
    "                    \"x\": 3.1,\n",
    "                    \"y\": 8.2,\n",
    "                    \"radiusX\": 20,\n",
    "                    \"radiusY\": 16,\n",
    "                    \"ellipselabels\": [\"Car\"]\n",
    "                }\n",
    "            }\n",
    "    \"\"\"\n",
    "    orig_annotations = None\n",
    "    with open(label_filename, \"r\") as f:\n",
    "        orig_annotations = json.load(f)\n",
    "\n",
    "    annotations = []\n",
    "    for annotation in orig_annotations:\n",
    "        # Process the label file, remove the first 9 random charactors \n",
    "        img_filename = os.path.basename(annotation[\"data\"][\"image\"])[9:]\n",
    "        \n",
    "        # Check whether images exist with TIFF format\n",
    "        filename, file_extension = os.path.splitext(img_filename)\n",
    "        tif_filename = filename + '.tif'\n",
    "        # if TIFF image file name starts with \"2020\", removes it\n",
    "        if tif_filename.startswith(\"2020\"):\n",
    "            tif_filename = tif_filename[4:]\n",
    "        tif_img_filepath = os.path.join(img_dir, tif_filename)\n",
    "        \n",
    "        if os.path.exists(tif_img_filepath):\n",
    "            annotations.append({\n",
    "                \"image\": tif_img_filepath,\n",
    "                \"annotations\": annotation[\"annotations\"][0][\"result\"]\n",
    "            }) \n",
    "        else:\n",
    "            print(\"Not exist: {}\".format(tif_img_filepath))\n",
    "    return annotations\n",
    "\n",
    "def gen_ellipse_from_annotation(label):\n",
    "    r\"\"\"\n",
    "    Generate ellipse from Label Studio ellipse annotation\n",
    "    Warning: this function only handles annotation with \"image_rotation\" = 0, otherwise, return False.\n",
    "\n",
    "    Returns a tuple of\n",
    "        - A bool flag to indicate whether the operation is successful\n",
    "        - ellipse center (x, y)\n",
    "        - ellipse axis (horizontal axis, vertical axis)\n",
    "        - ellipse angle\n",
    "        - category of the annotation\n",
    "\n",
    "    \"\"\"\n",
    "    image_rotation = label[\"image_rotation\"]\n",
    "    if image_rotation != 0:\n",
    "        return False, (0, 0), (0, 0), 0, \"\"\n",
    "    img_w, img_h = label[\"original_width\"], label[\"original_height\"]\n",
    "    rx, ry = label[\"value\"][\"radiusX\"] * img_w / 100, label[\"value\"][\"radiusY\"] * img_h / 100   # horizontal, verticle axies \n",
    "    # According to Label Studio, (x, y) coordinate of the top left corner before rotation (0, 100), but here it is actually the centre, weird.\n",
    "    cx, cy = label[\"value\"][\"x\"] * img_w / 100, label[\"value\"][\"y\"] * img_h / 100\n",
    "    angle = label[\"value\"][\"rotation\"]  # clockwise degree\n",
    "    category = label[\"value\"][\"ellipselabels\"][0]\n",
    "    return True, (cx, cy), (rx, ry), angle, category\n",
    "\n",
    "def gen_polygon_from_annotation(label, delta=10):\n",
    "    r\"\"\" \n",
    "    Generate polygon from Label Studio ellipse annotation\n",
    "    Warning: this function only handles annotation with \"image_rotation\" = 0, otherwise, return False.\n",
    "\n",
    "    Returns a tuple of\n",
    "        - A bool flag to indicate whether the operation is successful\n",
    "        - a closed polygon if successful, otherwise an empty list. E.g, [[x1, y1], [x2, y2], ...]\n",
    "        - category of the annotation\n",
    "\n",
    "    \"\"\"\n",
    "    success, center, axes, angle, category = gen_ellipse_from_annotation(label)\n",
    "    if success:\n",
    "        int_center = (int(center[0]), int(center[1]))\n",
    "        int_axes = (int(axes[0]), int(axes[1]))\n",
    "        int_angle = int(angle)\n",
    "        poly = cv2.ellipse2Poly(center=int_center, axes=int_axes, angle=int_angle, arcStart=0, arcEnd=360, delta=delta)\n",
    "        return True, poly, category\n",
    "    else:\n",
    "        return False, [], \"\"\n",
    "\n",
    "def gen_polygon_w_boundingbox_from_annotation(label, delta=10):\n",
    "    r\"\"\"\n",
    "    Generate polygon and non-rotated bounding_box from Label Studio ellipse annotation\n",
    "    Warning: this function only handles annotation with \"image_rotation\" = 0, otherwise, return False.\n",
    "\n",
    "    Returns a tuple of\n",
    "        - A bool flag to indicate whether the operation is successful\n",
    "        - a closed polygon if successful, otherwise an empty list. E.g, [[x1, y1], [x2, y2], ...]\n",
    "        - a bounding box in the format of (top_left_x, top_left_y, width, height)\n",
    "        - category of the annotation\n",
    "\n",
    "    \"\"\"\n",
    "    success, poly, category = gen_polygon_from_annotation(label, delta)\n",
    "    if success:\n",
    "        # bounding box format: (tlx, tly, w, h)\n",
    "        bb = cv2.boundingRect(poly)\n",
    "        return True, poly, bb, category\n",
    "    else:\n",
    "        return False, [], (0, 0, 0, 0), \"\"\n",
    "\n",
    "def draw_ellipses(img_filename, ellipses, categories, thickness=1):\n",
    "    img = cv2.imread(img_filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    tl = thickness\n",
    "    tf = max(tl-1, 1)\n",
    "    for e, category in zip(ellipses, categories):\n",
    "        color = random_color()\n",
    "        centerCoordinates = (int(e[0][0]), int(e[0][1]))\n",
    "        axesLength = (int(e[1][0]), int(e[1][1]))\n",
    "        angle = e[2]\n",
    "        cv2.ellipse(img, centerCoordinates, axesLength, angle, startAngle=0, endAngle=360, color=color, thickness=thickness)\n",
    "#         x, y, w, h = cv2.boundingRect(pts)\n",
    "#         cv2.rectangle(img, pt1=(x, y), pt2=(x+w, y+h), color=color, thickness=thickness, lineType=cv2.LINE_AA)\n",
    "#         t_size = cv2.getTextSize(category, 0, fontScale=tl/3, thickness=thickness)[0]\n",
    "#         c1 = (x, y)\n",
    "#         c2 = c1[0] + t_size[0], c1[1] - t_size[1] -3\n",
    "#         cv2.rectangle(img, c1, c2, color=color, thickness=-1, lineType=cv2.LINE_AA)  # filled\n",
    "#         cv2.putText(img, category, (c1[0], c1[1]-2), 0, tl/3, [255,255,255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "def draw_rotated_bboxes(img_filename, rboxes, texts, thickness=1, color=None):\n",
    "    img = cv2.imread(img_filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = draw_rotated_bboxes_on_image(img, rboxes, texts, thickness, color)\n",
    "    return img\n",
    "\n",
    "def draw_rotated_bboxes_on_image(img, rboxes, texts, thickness=1, color=None):\n",
    "    img_draw = img.copy()\n",
    "    tl = thickness\n",
    "    tf = max(tl-1, 1)\n",
    "    for rb, text in zip(rboxes, texts):\n",
    "        c = random_color() if color is None else color\n",
    "        box = cv2.boxPoints(rb)\n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(img_draw, [box], 0, color=c, thickness=thickness)\n",
    "        t_size = cv2.getTextSize(text, 0, fontScale=tl/3, thickness=thickness)[0]\n",
    "        pt = np.amin(box, axis=0)\n",
    "        c1 = (pt[0], pt[1])\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] -3\n",
    "        cv2.rectangle(img_draw, c1, c2, color=color, thickness=-1, lineType=cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img_draw, text, (c1[0], c1[1]-2), 0, tl/3, [255,255,255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    return img_draw\n",
    "    \n",
    "\n",
    "def draw_polygons(img_filename, polygons, categories, thickness=1):\n",
    "    img = cv2.imread(img_filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    tl = thickness\n",
    "    tf = max(tl-1, 1)\n",
    "    for p, category in zip(polygons, categories):\n",
    "        color = random_color()\n",
    "        pts_x = p[::2]\n",
    "        pts_y = p[1::2]\n",
    "        pts = [[x, y] for x,y in zip(pts_x, pts_y)]\n",
    "        pts = np.array(pts, np.int32)\n",
    "        cv2.polylines(img, [pts], isClosed=True, thickness=thickness, color=color)\n",
    "        # bounding box format: (tlx, tly, w, h)\n",
    "        x, y, w, h = cv2.boundingRect(pts)\n",
    "        cv2.rectangle(img, pt1=(x, y), pt2=(x+w, y+h), color=color, thickness=thickness, lineType=cv2.LINE_AA)\n",
    "        t_size = cv2.getTextSize(category, 0, fontScale=tl/3, thickness=thickness)[0]\n",
    "        c1 = (x, y)\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] -3\n",
    "        cv2.rectangle(img, c1, c2, color=color, thickness=-1, lineType=cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img, category, (c1[0], c1[1]-2), 0, tl/3, [255,255,255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "    \n",
    "\n",
    "def draw_labelstudio_annotations(img_filename, annotations, draw_polygon=True, draw_boundingbox=True, delta=10, thickness=1):\n",
    "    img = cv2.imread(img_filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # img_h, img_w = img.shape[:2]\n",
    "    # print(\"Image size = {}\".format((img_h, img_w)))\n",
    "    \n",
    "    tl = thickness\n",
    "    tf = max(tl-1, 1)\n",
    "    for v in annotations:\n",
    "        if draw_polygon:\n",
    "            success_poly, poly, category = gen_polygon_from_annotation(v)\n",
    "            if success_poly:\n",
    "                cv2.polylines(img, [poly], isClosed=True, thickness=thickness, color=COLORS[category])\n",
    "                # cv2.fillConvexPoly(img, poly, color=COLORS[category])\n",
    "                \n",
    "        if draw_boundingbox:\n",
    "            success_bb, _, (x, y, w, h), category = gen_polygon_w_boundingbox_from_annotation(v, delta=delta)\n",
    "            if success_bb:\n",
    "                cv2.rectangle(img, pt1=(x, y), pt2=(x+w, y+h), color=COLORS[category], thickness=thickness, lineType=cv2.LINE_AA)\n",
    "                t_size = cv2.getTextSize(category, 0, fontScale=tl/3, thickness=thickness)[0]\n",
    "                c1 = (x, y)\n",
    "                c2 = c1[0] + t_size[0], c1[1] - t_size[1] -3\n",
    "                cv2.rectangle(img, c1, c2, color=COLORS[category], thickness=-1, lineType=cv2.LINE_AA)  # filled\n",
    "                cv2.putText(img, category, (c1[0], c1[1]-2), 0, tl/3, [255,255,255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "def get_detectron2_dicts(img_dir, json_filename, delta=5):\n",
    "    labelstudio_annotations = filter_annotations(img_dir, json_filename)\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for idx, v in enumerate(labelstudio_annotations):\n",
    "        record = {}\n",
    "        img_filename = v[\"image\"]\n",
    "        annotations = v[\"annotations\"]\n",
    "        img_h, img_w = cv2.imread(img_filename).shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = img_filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = img_h\n",
    "        record[\"width\"] = img_w\n",
    "\n",
    "        objs = []\n",
    "        for anno in annotations:\n",
    "            if anno[\"original_width\"] != record[\"width\"] or anno[\"original_height\"] != record[\"height\"]:\n",
    "                print(\"Generate record error!\")\n",
    "                return []\n",
    "            \n",
    "            success, poly, _, category = gen_polygon_w_boundingbox_from_annotation(anno, delta=delta)\n",
    "            # Convert from [[x1, y1], [x2, y2], ...] to [x1, y1, x2, y2, ...]\n",
    "            px = [x for x, _ in poly]\n",
    "            py = [y for _, y in poly]\n",
    "            poly = [(float(x), float(y)) for x, y in poly]\n",
    "            poly = [p for x in poly for p in x]\n",
    "            if success:\n",
    "                if len(poly) <= 4:\n",
    "                    continue\n",
    "                obj = {\n",
    "                    \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                    \"segmentation\": [poly],\n",
    "                    \"category_id\": 0,  # single category\n",
    "                }\n",
    "                objs.append(obj)\n",
    "            else:\n",
    "                print(\"Generate record error!\")\n",
    "                return []\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    \n",
    "    return dataset_dicts\n",
    "\n",
    "\n",
    "def binary_mask_to_polygon(binary_mask, tolerance=0):\n",
    "    r\"\"\" Converts a binary mask to COCO polygon representation\n",
    "    Args:\n",
    "        binary_mask: a 2D binary numpy array where '1's represent the object\n",
    "        tolerance: Maximum distance from original points of polygon to approximated polygonal chain. If tolerance is 0, the original coordinate array is returned.\n",
    "    \n",
    "    \"\"\"\n",
    "    def close_contour(contour):\n",
    "        if not np.array_equal(contour[0], contour[-1]):\n",
    "            contour = np.vstack((contour, contour[0]))\n",
    "        return contour\n",
    "    \n",
    "    polygons = []\n",
    "    # pad mask to close contours of shapes which start and end at an edge\n",
    "    padded_binary_mask = np.pad(binary_mask, pad_width=1, mode='constant', constant_values=0)\n",
    "    contours = measure.find_contours(padded_binary_mask, 0.5)\n",
    "    for contour in contours:\n",
    "        contour = close_contour(contour)\n",
    "        if len(contour) < 3:\n",
    "            continue\n",
    "        contour = np.flip(contour, axis=1)\n",
    "        segmentation = contour.ravel().tolist()\n",
    "        # after padding and subtracting 1 we may get -0.5 points in our segmentation\n",
    "#         segmentation = [0 if i < 0 else i for i in segmentation]\n",
    "        polygons.append(segmentation)\n",
    "    return polygons\n",
    "\n",
    "def fit_polygens_to_ellipses(polygons):\n",
    "    ellipses = []\n",
    "    for p in polygons:\n",
    "        pts_x = p[::2]\n",
    "        pts_y = p[1::2]\n",
    "        pts = [[x, y] for x,y in zip(pts_x, pts_y)]\n",
    "        pts = np.array(pts, np.int32)\n",
    "        ellipses.append(cv2.fitEllipse(pts))\n",
    "    return ellipses\n",
    "\n",
    "def fit_polygens_to_rotated_bboxes(polygons):\n",
    "    rbboxes = []\n",
    "    for p in polygons:\n",
    "        pts_x = p[::2]\n",
    "        pts_y = p[1::2]\n",
    "        pts = [[x, y] for x,y in zip(pts_x, pts_y)]\n",
    "        pts = np.array(pts, np.float32)\n",
    "        rect = cv2.minAreaRect(pts)  #  ((cx, cy), (w, h), a)\n",
    "        rbboxes.append(rect)\n",
    "    return rbboxes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78404d04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset summary\n",
    "prj_path = pathlib.Path().absolute().parent\n",
    "\n",
    "dataset_name = \"stomata100\"\n",
    "\n",
    "json_filename = os.path.join(prj_path, \"{}/labels/labels.json\".format(dataset_name))\n",
    "\n",
    "full_img_dir = os.path.join(prj_path, \"{}/images\".format(dataset_name))\n",
    "train_img_dir = os.path.join(prj_path, \"{}/train\".format(dataset_name))\n",
    "val_img_dir = os.path.join(prj_path, \"{}/val\".format(dataset_name))\n",
    "\n",
    "labelstudio_annotations = filter_annotations(full_img_dir, json_filename)\n",
    "train_labelstudio_annotations = filter_annotations(train_img_dir, json_filename)\n",
    "val_labelstudio_annotations = filter_annotations(val_img_dir, json_filename)\n",
    "\n",
    "for ls_annotation in [labelstudio_annotations, train_labelstudio_annotations, val_labelstudio_annotations]:\n",
    "    summary = {}\n",
    "    for v in ls_annotation:\n",
    "        annotations = v[\"annotations\"]\n",
    "        for anno in annotations:\n",
    "            category = anno['value']['ellipselabels'][0]\n",
    "            if category in summary:\n",
    "                summary[category] += 1\n",
    "            else:\n",
    "                summary[category] = 1\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw ground truth on image data and save on local disk\n",
    "prj_path = pathlib.Path().absolute().parent\n",
    "dataset_name = \"stomata100\"\n",
    "json_filename = os.path.join(prj_path, \"{}/labels/labels.json\".format(dataset_name))\n",
    "\n",
    "full_img_dir = os.path.join(prj_path, \"{}/images\".format(dataset_name))\n",
    "train_img_dir = os.path.join(prj_path, \"{}/train\".format(dataset_name))\n",
    "val_img_dir = os.path.join(prj_path, \"{}/val\".format(dataset_name))\n",
    "\n",
    "labelstudio_annotations = filter_annotations(full_img_dir, json_filename)\n",
    "save_dir = os.path.join(prj_path, \"{}/images_w_gt\".format(dataset_name))\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for anno in labelstudio_annotations:\n",
    "    img_filename = anno[\"image\"]\n",
    "    annotations = anno[\"annotations\"]\n",
    "    img = draw_labelstudio_annotations(img_filename, annotations, thickness=2)\n",
    "    save_filename = os.path.join(save_dir, os.path.basename(img_filename))\n",
    "    cv2.imwrite(save_filename, cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a604c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_path = pathlib.Path().absolute().parent\n",
    "dataset_name = \"stomata100\"\n",
    "\n",
    "json_filename = os.path.join(prj_path, \"{}/labels/labels.json\".format(dataset_name))\n",
    "\n",
    "# Get Detectron2 ground truth\n",
    "for d in [\"train\", \"val\"]:\n",
    "    catelog_name = \"{}_{}\".format(dataset_name, d)\n",
    "    if catelog_name in DatasetCatalog:\n",
    "        DatasetCatalog.remove(catelog_name)\n",
    "    if catelog_name in MetadataCatalog:\n",
    "        MetadataCatalog.remove(catelog_name)\n",
    "    \n",
    "    img_dir = os.path.join(prj_path, catelog_name)\n",
    "    DatasetCatalog.register(catelog_name, \n",
    "        lambda d=d: get_detectron2_dicts(os.path.join(prj_path, \"{}/{}\".format(dataset_name, d)), json_filename))\n",
    "    MetadataCatalog.get(catelog_name).set(thing_classes=[\"stomata\"])\n",
    "\n",
    "stomata_metadata = MetadataCatalog.get(\"{}_train\".format(dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "\n",
    "dataset_name = \"stomata100\"\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"{}_train\".format(dataset_name),)\n",
    "cfg.DATASETS.TEST = (\"{}_val\".format(dataset_name), )\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1000    # you may need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (stomata). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.MODEL.DEVICE = \"cpu\"    # train with CPU\n",
    "\n",
    "\n",
    "model_folder_name = \"stomata100_output_ep8000_2022_10_06_04_36_29\"\n",
    "cfg.OUTPUT_DIR = \"./{}\".format(model_folder_name)\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e728db97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_name = \"stomata100\"\n",
    "\n",
    "for i in range(1,10):\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = i/10   # set a custom testing threshold\n",
    "    \n",
    "    save_dir = os.path.join(\n",
    "        prj_path, \n",
    "        \"{}/{}_val_outputs/thres_{}\".format(model_folder_name, dataset_name, cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST))\n",
    "    shutil.rmtree(save_dir, ignore_errors=True)\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    prj_path = pathlib.Path().absolute().parent\n",
    "    json_filename = os.path.join(prj_path, \"{}/labels/labels.json\".format(dataset_name))\n",
    "    full_img_dir = os.path.join(prj_path, \"{}/images\".format(dataset_name))\n",
    "    train_img_dir = os.path.join(prj_path, \"{}/train\".format(dataset_name))\n",
    "    val_img_dir = os.path.join(prj_path, \"{}/val\".format(dataset_name))\n",
    "\n",
    "    val_dataset_dicts = get_detectron2_dicts(val_img_dir, json_filename, delta=5)\n",
    "    labelstudio_annotations = filter_annotations(val_img_dir, json_filename)\n",
    "\n",
    "    for idx, d in enumerate(val_dataset_dicts):\n",
    "        im = cv2.imread(d[\"file_name\"])\n",
    "        outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "\n",
    "        v = Visualizer(im[:, :, ::-1],\n",
    "                        metadata=stomata_metadata,\n",
    "                        scale=1,\n",
    "    #                     instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "            )\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 8), dpi=300)\n",
    "        fig.add_subplot(1, 3, 1)\n",
    "        plt.imshow(out.get_image())\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Pred: {}\".format(os.path.basename(d[\"file_name\"])))\n",
    "\n",
    "        filename, file_extension = os.path.splitext(os.path.basename(d[\"file_name\"]))\n",
    "        # Set file extension to JPEG\n",
    "        file_extension = \".jpg\"\n",
    "        save_filename = os.path.join(\n",
    "            save_dir, \n",
    "            \"{}_thres_{}_inst_seg{}\".format(filename, cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST, file_extension))\n",
    "        cv2.imwrite(save_filename, cv2.cvtColor(out.get_image(), cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        \n",
    "        img_filename = labelstudio_annotations[idx][\"image\"]\n",
    "        annotations = labelstudio_annotations[idx][\"annotations\"]\n",
    "        \n",
    "        \n",
    "        pred_masks = outputs['instances'].pred_masks\n",
    "        pred_categories = outputs['instances'].pred_classes\n",
    "        pred_scores = outputs['instances'].scores\n",
    "        polygons, categories = [], []\n",
    "        for mask, category, score in zip(pred_masks, pred_categories, pred_scores):\n",
    "            po = binary_mask_to_polygon(mask)\n",
    "            polygons += po\n",
    "            categories += [\"stomata {:.0%}\".format(score)] * len(po)\n",
    "        \n",
    "        \n",
    "        # Draw fitted bounding boxes\n",
    "        fitted_rbboxs = fit_polygens_to_rotated_bboxes(polygons)\n",
    "        img_draw = draw_rotated_bboxes(img_filename, fitted_rbboxs, categories, thickness=2, color=None)\n",
    "        fig.add_subplot(1, 3, 2)\n",
    "        plt.imshow(img_draw)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Pred_rotated_bboxes: {}\".format(os.path.basename(d[\"file_name\"])))\n",
    "        save_filename = os.path.join(\n",
    "            save_dir, \n",
    "            \"{}_thres_{}_rotated_bbox{}\".format(filename, cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST, file_extension))\n",
    "        cv2.imwrite(save_filename, cv2.cvtColor(img_draw, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "\n",
    "        # Draw annotation ground truth\n",
    "        img = draw_labelstudio_annotations(img_filename, annotations, thickness=2)\n",
    "        fig.add_subplot(1, 3, 3)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Ground truth: {}\".format(os.path.basename(d[\"file_name\"])))\n",
    "        \n",
    "        save_filename = os.path.join(\n",
    "            save_dir, \n",
    "            \"benchmark_{}_thres_{}{}\".format(filename, cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST, file_extension))\n",
    "        fig.savefig(save_filename, bbox_inches='tight')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9193069f",
   "metadata": {},
   "source": [
    "We can also evaluate its performance using AP metric implemented in COCO API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f0dc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "dataset_name = \"stomata100\"\n",
    "\n",
    "split = \"{}_val\".format(dataset_name)\n",
    "\n",
    "results = []\n",
    "for i in range(1, 10):\n",
    "    thres = i/10\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = thres   # set a custom testing threshold\n",
    "    cfg.INPUT.MIN_SIZE_TEST = 0 # disable resize in testing\n",
    "    \n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    evaluator = COCOEvaluator(split, output_dir=cfg.OUTPUT_DIR)\n",
    "    val_loader = build_detection_test_loader(cfg, split)\n",
    "    dataset_result = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "    \n",
    "    res = {\n",
    "        \"thres\": thres,\n",
    "        \"bbox\": {\n",
    "            \"AP\": dataset_result['bbox']['AP'],\n",
    "            \"AP50\": dataset_result['bbox']['AP50'],\n",
    "            \"AP75\": dataset_result['bbox']['AP75'],\n",
    "        },\n",
    "        \"segm\": {\n",
    "            \"AP\":   dataset_result['segm']['AP'],\n",
    "            \"AP50\": dataset_result['segm']['AP50'],\n",
    "            \"AP75\": dataset_result['segm']['AP75'],\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results.append(res)\n",
    "    # another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de94822",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(cfg)\n",
    "\n",
    "for _, v in enumerate(results):\n",
    "    print(\"\\n==========================================\")\n",
    "    print(\"\\nThres = {}\".format(v[\"thres\"]))\n",
    "    print(\"\\n=== bbox ===\")\n",
    "    for k in [\"AP\", \"AP50\", \"AP75\"]:\n",
    "        print(\"{}: {}\".format(k, v[\"bbox\"][k]))\n",
    "    print(\"=== segm ===\")\n",
    "    for k in [\"AP\", \"AP50\", \"AP75\"]:\n",
    "        print(\"{}: {}\".format(k, v[\"segm\"][k]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
